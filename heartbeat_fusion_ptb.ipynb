{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from pyts.image import GramianAngularField\n",
    "from pyts.datasets import load_gunpoint\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.utils import resample\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks, NearMiss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.models import alexnet, vgg16, resnet152, resnet18, vgg19\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import classification_report, recall_score, f1_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_gaf = torch.load('res_net_test_recall_best_gaf.chk')\n",
    "res_net_gaf = resnet18(pretrained=True)\n",
    "for param in res_net_gaf.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = res_net_gaf.fc.in_features\n",
    "res_net_gaf.fc = nn.Sequential(\n",
    "                nn.Linear(in_features=num_ftrs, out_features=256, bias=False),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=256, out_features=128, bias=True),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=128, out_features=5, bias=True))\n",
    "res_net_gaf.load_state_dict(ckpt_gaf['net'])\n",
    "res_net_gaf.fc = Identity()\n",
    "res_net_gaf.cuda()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_rp = torch.load('res_net_test_recall_best_rp.chk')\n",
    "res_net_rp = resnet18(pretrained=True)\n",
    "for param in res_net_rp.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = res_net_rp.fc.in_features\n",
    "res_net_rp.fc = nn.Sequential(\n",
    "                nn.Linear(in_features=num_ftrs, out_features=256, bias=False),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=256, out_features=128, bias=True),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=128, out_features=5, bias=True))\n",
    "res_net_rp.load_state_dict(ckpt_rp['net'])\n",
    "res_net_rp.fc = Identity()\n",
    "res_net_rp.cuda()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for moving tensor or model to GPU\n",
    "def cuda(xs):\n",
    "    if torch.cuda.is_available():\n",
    "        if not isinstance(xs, (list, tuple)):\n",
    "            return xs.cuda()\n",
    "        else:\n",
    "            return [x.cuda() for x in xs]\n",
    "    else:\n",
    "        return xs\n",
    "\n",
    "# Custom class for defining dataset for training with augmentation\n",
    "class Dataset_Hdf5(Dataset):\n",
    "\n",
    "    def __init__(self, path, data_type):\n",
    "        \"\"\" Intialize the dataset\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.file = h5py.File(path, 'r')\n",
    "        self.images = self.file['x_{}'.format(data_type)]\n",
    "        self.labels = self.file['y_{}'.format(data_type)]\n",
    "                \n",
    "        self.len = self.images.shape[0]\n",
    "        if data_type == 'train':\n",
    "            # no augmentation as we are transforming heartbeats to images via gramian angular field\n",
    "            self.transform = transforms.Compose([\n",
    "#                                               transforms.ToPILImage(),\n",
    "#                                               transforms.RandomRotation((0, 360)),\n",
    "#                                               transforms.RandomHorizontalFlip(),\n",
    "#                                               transforms.RandomVerticalFlip(),\n",
    "                                              transforms.ToTensor()])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    # You must override __getitem__ and __len__\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get a sample from the dataset\n",
    "        \"\"\"\n",
    "        # unsqueeze adds dimension to image -> converts to 1x224x224 since we don't have rgb\n",
    "        return self.transform(self.images[index].astype('float32')), \\\n",
    "                torch.tensor(self.labels[index], dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of samples in the dataset\n",
    "        \"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_train_loader_bln_3 = torch.utils.data.DataLoader(Dataset_Hdf5('/home/asif/heartbeat/hb_data_ptb.hdf5', 'train'), \n",
    "                                                batch_size=512, shuffle=True)\n",
    "hb_test_loader_bln_3 = torch.utils.data.DataLoader(Dataset_Hdf5('/home/asif/heartbeat/hb_data_ptb.hdf5', 'test'), \n",
    "                                                batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_train_loader_bln_4 = torch.utils.data.DataLoader(Dataset_Hdf5('/home/asif/heartbeat/hb_data_ptb_rp.hdf5', 'train'), \n",
    "                                                batch_size=512, shuffle=False)\n",
    "hb_test_loader_bln_4 = torch.utils.data.DataLoader(Dataset_Hdf5('/home/asif/heartbeat/hb_data_ptb_rp.hdf5', 'test'), \n",
    "                                                batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 11641\n",
    "test_size = 2911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11641\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('hb_gaf_rp_ptb_intermediate.hdf5', mode='w') as hdf5_file:\n",
    "    hdf5_file.create_dataset(\"x_train\", (train_size, 1024), np.float32)\n",
    "    hdf5_file.create_dataset(\"y_train\", (train_size,), np.int32)\n",
    "    hdf5_file.create_dataset(\"x_test\", (test_size, 1024), np.float32)\n",
    "    hdf5_file.create_dataset(\"y_test\", (test_size,), np.int32)\n",
    "    \n",
    "    index = 0\n",
    "    for _, (data_gaf, data_rp) in enumerate(zip(hb_train_loader_bln_3, hb_train_loader_bln_4), 0):\n",
    "        inputs_gaf, labels = cuda(data_gaf)\n",
    "        inputs_rp, _ = cuda(data_rp)\n",
    "        outputs_gaf = res_net_gaf(inputs_gaf.expand(-1, 3, -1, -1))\n",
    "        outputs_rp = res_net_rp(inputs_rp.expand(-1, 3, -1, -1))\n",
    "        hdf5_file[\"x_train\"][index:index + outputs_gaf.shape[0], :512] = outputs_gaf.cpu().numpy()\n",
    "        hdf5_file[\"x_train\"][index:index + outputs_rp.shape[0], 512:1024] = outputs_rp.cpu().numpy()\n",
    "        hdf5_file[\"y_train\"][index:index + outputs_gaf.shape[0]] = labels.cpu().numpy()\n",
    "        index += outputs_gaf.shape[0]\n",
    "    print(index)\n",
    "    index = 0\n",
    "    for _, (data_gaf, data_rp) in enumerate(zip(hb_test_loader_bln_3, hb_test_loader_bln_4), 0):\n",
    "        inputs_gaf, labels = cuda(data_gaf)\n",
    "        inputs_rp, _ = cuda(data_rp)\n",
    "        outputs_gaf = res_net_gaf(inputs_gaf.expand(-1, 3, -1, -1))\n",
    "        outputs_rp = res_net_rp(inputs_rp.expand(-1, 3, -1, -1))\n",
    "        hdf5_file[\"x_test\"][index:index + outputs_gaf.shape[0], :512] = outputs_gaf.cpu().numpy()\n",
    "        hdf5_file[\"x_test\"][index:index + outputs_rp.shape[0], 512:1024] = outputs_rp.cpu().numpy()\n",
    "        hdf5_file[\"y_test\"][index:index + outputs_gaf.shape[0]] = labels.cpu().numpy()\n",
    "        index += outputs_gaf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1024, out_features=512, bias=False)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "                nn.Linear(in_features=1024, out_features=512, bias=False),\n",
    "                nn.ReLU(),\n",
    "#                 nn.Dropout(p=0.5),\n",
    "                nn.Linear(in_features=512, out_features=256, bias=False),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=256, out_features=128, bias=True),\n",
    "                nn.ReLU(),\n",
    "#                 nn.Dropout(p=0.5),\n",
    "                nn.Linear(in_features=128, out_features=2, bias=True))\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom class for defining dataset for training with augmentation\n",
    "class DatasetFusion(Dataset):\n",
    "\n",
    "    def __init__(self, path, data_type):\n",
    "        \"\"\" Intialize the dataset\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.file = h5py.File(path, 'r')\n",
    "        self.images = self.file['x_{}'.format(data_type)]\n",
    "        self.labels = self.file['y_{}'.format(data_type)]\n",
    "                \n",
    "        self.len = self.images.shape[0]\n",
    "        if data_type == 'train':\n",
    "            # no augmentation as we are transforming heartbeats to images via gramian angular field\n",
    "            self.transform = transforms.Compose([\n",
    "\n",
    "                                              transforms.ToTensor()])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    # You must override __getitem__ and __len__\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get a sample from the dataset\n",
    "        \"\"\"\n",
    "        # unsqueeze adds dimension to image -> converts to 1x224x224 since we don't have rgb\n",
    "        return torch.tensor(self.images[index].astype('float32')), \\\n",
    "                torch.tensor(self.labels[index], dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of samples in the dataset\n",
    "        \"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_train_loader = torch.utils.data.DataLoader(DatasetFusion('/home/asif/heartbeat/hb_gaf_rp_ptb_intermediate.hdf5', 'train'), \n",
    "                                                batch_size=512, shuffle=True)\n",
    "hb_test_loader = torch.utils.data.DataLoader(DatasetFusion('/home/asif/heartbeat/hb_gaf_rp_ptb_intermediate.hdf5', 'test'), \n",
    "                                                batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = cuda(torch.tensor([2.0, 1.0]))\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([\n",
    "                                          {\"params\": net[0].parameters(), \"lr\": 0.001},\n",
    "                                          {\"params\": net[2].parameters(), \"lr\": 0.001},\n",
    "                                          {\"params\": net[4].parameters(), \"lr\": 0.002},\n",
    "#                                           {\"params\": net[6].parameters(), \"lr\": 0.002},\n",
    "                                           ],\n",
    "                                lr=0.001, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_loader, criterion, optimizer, test_loader, num_epochs=25):\n",
    "    net.train()\n",
    "    train_acc_max = 0\n",
    "    test_acc_max = 0\n",
    "    recall_max = 0\n",
    "    f1_max = 0\n",
    "\n",
    "#     scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.95)\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        \n",
    "        net.train()\n",
    "\n",
    "        total = 0\n",
    "        correct = 0\n",
    "   \n",
    "        running_loss = 0.0\n",
    "    \n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            \n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            \n",
    "            inputs, labels = cuda(data)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs) # already in RGB\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "#         scheduler.step()\n",
    "        \n",
    "        print('End of epoch {}, Loss {}'.format(epoch + 1, running_loss / len(train_loader)))\n",
    "        \n",
    "        train_acc = correct / total\n",
    "        print('Train accuracy: {}'.format(train_acc))\n",
    "        test_acc, all_true, all_pred = test(net, test_loader)\n",
    "        print('Test accuracy: {}'.format(test_acc))\n",
    "        print(classification_report(all_true, all_pred, target_names=['N', 'A']))\n",
    "        recall = recall_score(all_true, all_pred, average='macro')\n",
    "        f1 = f1_score(all_true, all_pred, average='macro')\n",
    "        \n",
    "        # Saving best checkpoint based on performance on test data            \n",
    "        if recall > recall_max:\n",
    "            recall_max = recall\n",
    "            save_checkpoint(epoch + 1, net, optimizer, train_acc, test_acc, recall, f1, 'fc_net_fusion', 'test_recall')\n",
    "            \n",
    "        if f1 > f1_max:\n",
    "            f1_max = f1\n",
    "            save_checkpoint(epoch + 1, net, optimizer, train_acc, test_acc, recall, f1, 'fc_net_fusion', 'test_f1')\n",
    "\n",
    "    print('Finished Training')\n",
    "    \n",
    "def test(net, test_loader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "            inputs, labels = cuda(data)\n",
    "            all_true.extend(labels.cpu().tolist())\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_pred.extend(predicted.cpu().tolist())\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = correct / total\n",
    "#     print('Accuracy of the network on the images: %d %%' % (100 * acc))\n",
    "    return acc, all_true, all_pred\n",
    "\n",
    "def save_checkpoint(epoch, net, optimizer, train_acc, test_acc, recall, f1, net_name, param):\n",
    "    checkpoint = {\n",
    "        'net': net.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "    torch.save(checkpoint, '{}_{}_best.chk'.format(net_name, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 1, Loss 0.2868299581434416\n",
      "Train accuracy: 0.8842882913839017\n",
      "Test accuracy: 0.8450704225352113\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.66      0.91      0.76       809\n",
      "           A       0.96      0.82      0.88      2102\n",
      "\n",
      "    accuracy                           0.85      2911\n",
      "   macro avg       0.81      0.86      0.82      2911\n",
      "weighted avg       0.88      0.85      0.85      2911\n",
      "\n",
      "End of epoch 2, Loss 0.2805394109176553\n",
      "Train accuracy: 0.8836869684734988\n",
      "Test accuracy: 0.889385091034009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.79      0.83      0.81       809\n",
      "           A       0.93      0.91      0.92      2102\n",
      "\n",
      "    accuracy                           0.89      2911\n",
      "   macro avg       0.86      0.87      0.86      2911\n",
      "weighted avg       0.89      0.89      0.89      2911\n",
      "\n",
      "End of epoch 3, Loss 0.27650885867035907\n",
      "Train accuracy: 0.8853191306588781\n",
      "Test accuracy: 0.8849192717279285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.80      0.78      0.79       809\n",
      "           A       0.92      0.93      0.92      2102\n",
      "\n",
      "    accuracy                           0.88      2911\n",
      "   macro avg       0.86      0.85      0.86      2911\n",
      "weighted avg       0.88      0.88      0.88      2911\n",
      "\n",
      "End of epoch 4, Loss 0.29301656717839447\n",
      "Train accuracy: 0.875697964092432\n",
      "Test accuracy: 0.8601855032634833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.71      0.85      0.77       809\n",
      "           A       0.94      0.86      0.90      2102\n",
      "\n",
      "    accuracy                           0.86      2911\n",
      "   macro avg       0.82      0.86      0.84      2911\n",
      "weighted avg       0.87      0.86      0.86      2911\n",
      "\n",
      "End of epoch 5, Loss 0.2831291271292645\n",
      "Train accuracy: 0.8846319044755605\n",
      "Test accuracy: 0.8612160769495019\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.70      0.86      0.78       809\n",
      "           A       0.94      0.86      0.90      2102\n",
      "\n",
      "    accuracy                           0.86      2911\n",
      "   macro avg       0.82      0.86      0.84      2911\n",
      "weighted avg       0.88      0.86      0.87      2911\n",
      "\n",
      "End of epoch 6, Loss 0.2517021466856417\n",
      "Train accuracy: 0.8985482346877416\n",
      "Test accuracy: 0.8505668155273102\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.67      0.91      0.77       809\n",
      "           A       0.96      0.83      0.89      2102\n",
      "\n",
      "    accuracy                           0.85      2911\n",
      "   macro avg       0.82      0.87      0.83      2911\n",
      "weighted avg       0.88      0.85      0.86      2911\n",
      "\n",
      "End of epoch 7, Loss 0.2637951950664106\n",
      "Train accuracy: 0.889356584485869\n",
      "Test accuracy: 0.8570937822054276\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.78      0.68      0.73       809\n",
      "           A       0.88      0.92      0.90      2102\n",
      "\n",
      "    accuracy                           0.86      2911\n",
      "   macro avg       0.83      0.80      0.81      2911\n",
      "weighted avg       0.85      0.86      0.85      2911\n",
      "\n",
      "End of epoch 8, Loss 0.2500300504591154\n",
      "Train accuracy: 0.895885233227386\n",
      "Test accuracy: 0.8804534524218481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.74      0.87      0.80       809\n",
      "           A       0.95      0.88      0.91      2102\n",
      "\n",
      "    accuracy                           0.88      2911\n",
      "   macro avg       0.84      0.88      0.86      2911\n",
      "weighted avg       0.89      0.88      0.88      2911\n",
      "\n",
      "End of epoch 9, Loss 0.25467857653680054\n",
      "Train accuracy: 0.8951121037711537\n",
      "Test accuracy: 0.8777052559257987\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.77      0.79      0.78       809\n",
      "           A       0.92      0.91      0.91      2102\n",
      "\n",
      "    accuracy                           0.88      2911\n",
      "   macro avg       0.85      0.85      0.85      2911\n",
      "weighted avg       0.88      0.88      0.88      2911\n",
      "\n",
      "End of epoch 10, Loss 0.2445922403231911\n",
      "Train accuracy: 0.8978610085044241\n",
      "Test accuracy: 0.8746135348677431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.73      0.88      0.80       809\n",
      "           A       0.95      0.87      0.91      2102\n",
      "\n",
      "    accuracy                           0.87      2911\n",
      "   macro avg       0.84      0.88      0.85      2911\n",
      "weighted avg       0.89      0.87      0.88      2911\n",
      "\n",
      "End of epoch 11, Loss 0.23439862546713455\n",
      "Train accuracy: 0.9012112361480973\n",
      "Test accuracy: 0.8907591892820337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.86      0.72      0.79       809\n",
      "           A       0.90      0.96      0.93      2102\n",
      "\n",
      "    accuracy                           0.89      2911\n",
      "   macro avg       0.88      0.84      0.86      2911\n",
      "weighted avg       0.89      0.89      0.89      2911\n",
      "\n",
      "End of epoch 12, Loss 0.2492413844751275\n",
      "Train accuracy: 0.8940812644961773\n",
      "Test accuracy: 0.8715218138096874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.86      0.64      0.73       809\n",
      "           A       0.87      0.96      0.92      2102\n",
      "\n",
      "    accuracy                           0.87      2911\n",
      "   macro avg       0.87      0.80      0.82      2911\n",
      "weighted avg       0.87      0.87      0.86      2911\n",
      "\n",
      "End of epoch 13, Loss 0.2649016736642174\n",
      "Train accuracy: 0.8878103255734043\n",
      "Test accuracy: 0.8945379594641016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.79      0.84      0.82       809\n",
      "           A       0.94      0.91      0.93      2102\n",
      "\n",
      "    accuracy                           0.89      2911\n",
      "   macro avg       0.86      0.88      0.87      2911\n",
      "weighted avg       0.90      0.89      0.90      2911\n",
      "\n",
      "End of epoch 14, Loss 0.2521283101776372\n",
      "Train accuracy: 0.8911605532170775\n",
      "Test accuracy: 0.8718653383716936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.71      0.90      0.80       809\n",
      "           A       0.96      0.86      0.91      2102\n",
      "\n",
      "    accuracy                           0.87      2911\n",
      "   macro avg       0.84      0.88      0.85      2911\n",
      "weighted avg       0.89      0.87      0.88      2911\n",
      "\n",
      "End of epoch 15, Loss 0.22304677963256836\n",
      "Train accuracy: 0.9079975947083584\n",
      "Test accuracy: 0.881827550669873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.82      0.73      0.78       809\n",
      "           A       0.90      0.94      0.92      2102\n",
      "\n",
      "    accuracy                           0.88      2911\n",
      "   macro avg       0.86      0.84      0.85      2911\n",
      "weighted avg       0.88      0.88      0.88      2911\n",
      "\n",
      "End of epoch 16, Loss 0.22548492188039032\n",
      "Train accuracy: 0.9026715917876471\n",
      "Test accuracy: 0.8914462384060461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.77      0.87      0.82       809\n",
      "           A       0.95      0.90      0.92      2102\n",
      "\n",
      "    accuracy                           0.89      2911\n",
      "   macro avg       0.86      0.88      0.87      2911\n",
      "weighted avg       0.90      0.89      0.89      2911\n",
      "\n",
      "End of epoch 17, Loss 0.2305276147697283\n",
      "Train accuracy: 0.9037024310626235\n",
      "Test accuracy: 0.887667468223978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.79      0.82      0.80       809\n",
      "           A       0.93      0.91      0.92      2102\n",
      "\n",
      "    accuracy                           0.89      2911\n",
      "   macro avg       0.86      0.87      0.86      2911\n",
      "weighted avg       0.89      0.89      0.89      2911\n",
      "\n",
      "End of epoch 18, Loss 0.22485958169335904\n",
      "Train accuracy: 0.9048191736105146\n",
      "Test accuracy: 0.8821710752318791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.73      0.91      0.81       809\n",
      "           A       0.96      0.87      0.91      2102\n",
      "\n",
      "    accuracy                           0.88      2911\n",
      "   macro avg       0.85      0.89      0.86      2911\n",
      "weighted avg       0.90      0.88      0.89      2911\n",
      "\n",
      "End of epoch 19, Loss 0.22511595552382263\n",
      "Train accuracy: 0.9049050768834292\n",
      "Test accuracy: 0.8814840261078667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.73      0.91      0.81       809\n",
      "           A       0.96      0.87      0.91      2102\n",
      "\n",
      "    accuracy                           0.88      2911\n",
      "   macro avg       0.85      0.89      0.86      2911\n",
      "weighted avg       0.90      0.88      0.88      2911\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 20, Loss 0.2434803992509842\n",
      "Train accuracy: 0.8980328150502535\n",
      "Test accuracy: 0.8526279628993473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.68      0.90      0.77       809\n",
      "           A       0.95      0.84      0.89      2102\n",
      "\n",
      "    accuracy                           0.85      2911\n",
      "   macro avg       0.82      0.87      0.83      2911\n",
      "weighted avg       0.88      0.85      0.86      2911\n",
      "\n",
      "End of epoch 21, Loss 0.19546976685523987\n",
      "Train accuracy: 0.9171892449102311\n",
      "Test accuracy: 0.8790793541738234\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.73      0.89      0.80       809\n",
      "           A       0.95      0.88      0.91      2102\n",
      "\n",
      "    accuracy                           0.88      2911\n",
      "   macro avg       0.84      0.88      0.86      2911\n",
      "weighted avg       0.89      0.88      0.88      2911\n",
      "\n",
      "End of epoch 22, Loss 0.2267635393401851\n",
      "Train accuracy: 0.8999226870543767\n",
      "Test accuracy: 0.8880109927859842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.76      0.87      0.81       809\n",
      "           A       0.95      0.89      0.92      2102\n",
      "\n",
      "    accuracy                           0.89      2911\n",
      "   macro avg       0.85      0.88      0.87      2911\n",
      "weighted avg       0.90      0.89      0.89      2911\n",
      "\n",
      "End of epoch 23, Loss 0.21050762935825015\n",
      "Train accuracy: 0.9087707241645907\n",
      "Test accuracy: 0.887667468223978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.77      0.84      0.81       809\n",
      "           A       0.94      0.90      0.92      2102\n",
      "\n",
      "    accuracy                           0.89      2911\n",
      "   macro avg       0.86      0.87      0.86      2911\n",
      "weighted avg       0.89      0.89      0.89      2911\n",
      "\n",
      "End of epoch 24, Loss 0.19745780916317648\n",
      "Train accuracy: 0.9155570827248518\n",
      "Test accuracy: 0.8955685331501202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.82      0.80      0.81       809\n",
      "           A       0.92      0.93      0.93      2102\n",
      "\n",
      "    accuracy                           0.90      2911\n",
      "   macro avg       0.87      0.87      0.87      2911\n",
      "weighted avg       0.89      0.90      0.90      2911\n",
      "\n",
      "End of epoch 25, Loss 0.24217453793339108\n",
      "Train accuracy: 0.9041319474271969\n",
      "Test accuracy: 0.8917897629680522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.77      0.87      0.82       809\n",
      "           A       0.95      0.90      0.92      2102\n",
      "\n",
      "    accuracy                           0.89      2911\n",
      "   macro avg       0.86      0.88      0.87      2911\n",
      "weighted avg       0.90      0.89      0.89      2911\n",
      "\n",
      "End of epoch 26, Loss 0.19359923478053964\n",
      "Train accuracy: 0.9171892449102311\n",
      "Test accuracy: 0.8753005839917554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.83      0.70      0.76       809\n",
      "           A       0.89      0.94      0.92      2102\n",
      "\n",
      "    accuracy                           0.88      2911\n",
      "   macro avg       0.86      0.82      0.84      2911\n",
      "weighted avg       0.87      0.88      0.87      2911\n",
      "\n",
      "End of epoch 27, Loss 0.20327089662137238\n",
      "Train accuracy: 0.9136672107207284\n",
      "Test accuracy: 0.8835451734799038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.74      0.89      0.81       809\n",
      "           A       0.95      0.88      0.92      2102\n",
      "\n",
      "    accuracy                           0.88      2911\n",
      "   macro avg       0.85      0.89      0.86      2911\n",
      "weighted avg       0.90      0.88      0.89      2911\n",
      "\n",
      "End of epoch 28, Loss 0.19684784503086752\n",
      "Train accuracy: 0.9170174383644016\n",
      "Test accuracy: 0.8533150120233597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.92      0.52      0.66       809\n",
      "           A       0.84      0.98      0.91      2102\n",
      "\n",
      "    accuracy                           0.85      2911\n",
      "   macro avg       0.88      0.75      0.78      2911\n",
      "weighted avg       0.86      0.85      0.84      2911\n",
      "\n",
      "End of epoch 29, Loss 0.19718808583591296\n",
      "Train accuracy: 0.9175328580018899\n",
      "Test accuracy: 0.8443833734111988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.66      0.92      0.77       809\n",
      "           A       0.97      0.81      0.88      2102\n",
      "\n",
      "    accuracy                           0.84      2911\n",
      "   macro avg       0.81      0.87      0.83      2911\n",
      "weighted avg       0.88      0.84      0.85      2911\n",
      "\n",
      "End of epoch 30, Loss 0.20414104668990427\n",
      "Train accuracy: 0.9125504681728374\n",
      "Test accuracy: 0.8907591892820337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.79      0.82      0.81       809\n",
      "           A       0.93      0.92      0.92      2102\n",
      "\n",
      "    accuracy                           0.89      2911\n",
      "   macro avg       0.86      0.87      0.87      2911\n",
      "weighted avg       0.89      0.89      0.89      2911\n",
      "\n",
      "End of epoch 31, Loss 0.1803681863390881\n",
      "Train accuracy: 0.9262949918391891\n",
      "Test accuracy: 0.895225008588114\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.83      0.79      0.81       809\n",
      "           A       0.92      0.94      0.93      2102\n",
      "\n",
      "    accuracy                           0.90      2911\n",
      "   macro avg       0.87      0.86      0.87      2911\n",
      "weighted avg       0.89      0.90      0.89      2911\n",
      "\n",
      "End of epoch 32, Loss 0.19895416239033575\n",
      "Train accuracy: 0.918048277639378\n",
      "Test accuracy: 0.8728959120577121\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.71      0.90      0.80       809\n",
      "           A       0.96      0.86      0.91      2102\n",
      "\n",
      "    accuracy                           0.87      2911\n",
      "   macro avg       0.84      0.88      0.85      2911\n",
      "weighted avg       0.89      0.87      0.88      2911\n",
      "\n",
      "End of epoch 33, Loss 0.19066877533560214\n",
      "Train accuracy: 0.9226011511038571\n",
      "Test accuracy: 0.867055994503607\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.71      0.89      0.79       809\n",
      "           A       0.95      0.86      0.90      2102\n",
      "\n",
      "    accuracy                           0.87      2911\n",
      "   macro avg       0.83      0.87      0.85      2911\n",
      "weighted avg       0.88      0.87      0.87      2911\n",
      "\n",
      "End of epoch 34, Loss 0.17185517692047617\n",
      "Train accuracy: 0.9280989605703978\n",
      "Test accuracy: 0.8911027138440398\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.78      0.86      0.81       809\n",
      "           A       0.94      0.90      0.92      2102\n",
      "\n",
      "    accuracy                           0.89      2911\n",
      "   macro avg       0.86      0.88      0.87      2911\n",
      "weighted avg       0.90      0.89      0.89      2911\n",
      "\n",
      "End of epoch 35, Loss 0.17012735035108484\n",
      "Train accuracy: 0.9279271540245684\n",
      "Test accuracy: 0.8845757471659224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.74      0.91      0.81       809\n",
      "           A       0.96      0.88      0.92      2102\n",
      "\n",
      "    accuracy                           0.88      2911\n",
      "   macro avg       0.85      0.89      0.86      2911\n",
      "weighted avg       0.90      0.88      0.89      2911\n",
      "\n",
      "End of epoch 36, Loss 0.21861848818219226\n",
      "Train accuracy: 0.9134095009019844\n",
      "Test accuracy: 0.8945379594641016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.83      0.78      0.80       809\n",
      "           A       0.92      0.94      0.93      2102\n",
      "\n",
      "    accuracy                           0.89      2911\n",
      "   macro avg       0.87      0.86      0.87      2911\n",
      "weighted avg       0.89      0.89      0.89      2911\n",
      "\n",
      "End of epoch 37, Loss 0.20931075513362885\n",
      "Train accuracy: 0.916931535091487\n",
      "Test accuracy: 0.8505668155273102\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.68      0.86      0.76       809\n",
      "           A       0.94      0.85      0.89      2102\n",
      "\n",
      "    accuracy                           0.85      2911\n",
      "   macro avg       0.81      0.85      0.83      2911\n",
      "weighted avg       0.87      0.85      0.86      2911\n",
      "\n",
      "End of epoch 38, Loss 0.18263617093148438\n",
      "Train accuracy: 0.925178249291298\n",
      "Test accuracy: 0.8976296805221573\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.83      0.79      0.81       809\n",
      "           A       0.92      0.94      0.93      2102\n",
      "\n",
      "    accuracy                           0.90      2911\n",
      "   macro avg       0.88      0.87      0.87      2911\n",
      "weighted avg       0.90      0.90      0.90      2911\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 39, Loss 0.1487905373391898\n",
      "Train accuracy: 0.9390086762305644\n",
      "Test accuracy: 0.8488491927172793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.92      0.50      0.65       809\n",
      "           A       0.84      0.98      0.90      2102\n",
      "\n",
      "    accuracy                           0.85      2911\n",
      "   macro avg       0.88      0.74      0.78      2911\n",
      "weighted avg       0.86      0.85      0.83      2911\n",
      "\n",
      "End of epoch 40, Loss 0.24350104254225027\n",
      "Train accuracy: 0.8982046215960828\n",
      "Test accuracy: 0.8856063208519409\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.76      0.85      0.81       809\n",
      "           A       0.94      0.90      0.92      2102\n",
      "\n",
      "    accuracy                           0.89      2911\n",
      "   macro avg       0.85      0.88      0.86      2911\n",
      "weighted avg       0.89      0.89      0.89      2911\n",
      "\n",
      "End of epoch 41, Loss 0.16063647101754727\n",
      "Train accuracy: 0.9344558027660854\n",
      "Test accuracy: 0.8873239436619719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.89      0.68      0.77       809\n",
      "           A       0.89      0.97      0.93      2102\n",
      "\n",
      "    accuracy                           0.89      2911\n",
      "   macro avg       0.89      0.82      0.85      2911\n",
      "weighted avg       0.89      0.89      0.88      2911\n",
      "\n",
      "End of epoch 42, Loss 0.15641472294278766\n",
      "Train accuracy: 0.9347135125848295\n",
      "Test accuracy: 0.8990037787701821\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.86      0.76      0.81       809\n",
      "           A       0.91      0.95      0.93      2102\n",
      "\n",
      "    accuracy                           0.90      2911\n",
      "   macro avg       0.89      0.86      0.87      2911\n",
      "weighted avg       0.90      0.90      0.90      2911\n",
      "\n",
      "End of epoch 43, Loss 0.1474237108360166\n",
      "Train accuracy: 0.9378919336826733\n",
      "Test accuracy: 0.8935073857780831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.88      0.71      0.79       809\n",
      "           A       0.90      0.96      0.93      2102\n",
      "\n",
      "    accuracy                           0.89      2911\n",
      "   macro avg       0.89      0.84      0.86      2911\n",
      "weighted avg       0.89      0.89      0.89      2911\n",
      "\n",
      "End of epoch 44, Loss 0.1461051378561103\n",
      "Train accuracy: 0.9375483205910146\n",
      "Test accuracy: 0.8993473033321883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.84      0.79      0.81       809\n",
      "           A       0.92      0.94      0.93      2102\n",
      "\n",
      "    accuracy                           0.90      2911\n",
      "   macro avg       0.88      0.87      0.87      2911\n",
      "weighted avg       0.90      0.90      0.90      2911\n",
      "\n",
      "End of epoch 45, Loss 0.19415030174929163\n",
      "Train accuracy: 0.9196804398247573\n",
      "Test accuracy: 0.8849192717279285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.76      0.85      0.80       809\n",
      "           A       0.94      0.90      0.92      2102\n",
      "\n",
      "    accuracy                           0.88      2911\n",
      "   macro avg       0.85      0.87      0.86      2911\n",
      "weighted avg       0.89      0.88      0.89      2911\n",
      "\n",
      "End of epoch 46, Loss 0.1327300651565842\n",
      "Train accuracy: 0.9458809380637402\n",
      "Test accuracy: 0.8948814840261079\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.88      0.72      0.79       809\n",
      "           A       0.90      0.96      0.93      2102\n",
      "\n",
      "    accuracy                           0.89      2911\n",
      "   macro avg       0.89      0.84      0.86      2911\n",
      "weighted avg       0.89      0.89      0.89      2911\n",
      "\n",
      "End of epoch 47, Loss 0.1439067753760711\n",
      "Train accuracy: 0.9378060304097586\n",
      "Test accuracy: 0.9027825489522501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.84      0.80      0.82       809\n",
      "           A       0.93      0.94      0.93      2102\n",
      "\n",
      "    accuracy                           0.90      2911\n",
      "   macro avg       0.88      0.87      0.88      2911\n",
      "weighted avg       0.90      0.90      0.90      2911\n",
      "\n",
      "End of epoch 48, Loss 0.14714427065590155\n",
      "Train accuracy: 0.936259771497294\n",
      "Test accuracy: 0.8917897629680522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.77      0.87      0.82       809\n",
      "           A       0.95      0.90      0.92      2102\n",
      "\n",
      "    accuracy                           0.89      2911\n",
      "   macro avg       0.86      0.89      0.87      2911\n",
      "weighted avg       0.90      0.89      0.89      2911\n",
      "\n",
      "End of epoch 49, Loss 0.11708296770634859\n",
      "Train accuracy: 0.9514646508031956\n",
      "Test accuracy: 0.9014084507042254\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.81      0.84      0.83       809\n",
      "           A       0.94      0.92      0.93      2102\n",
      "\n",
      "    accuracy                           0.90      2911\n",
      "   macro avg       0.87      0.88      0.88      2911\n",
      "weighted avg       0.90      0.90      0.90      2911\n",
      "\n",
      "End of epoch 50, Loss 0.15000599072031354\n",
      "Train accuracy: 0.9381496435014174\n",
      "Test accuracy: 0.8928203366540708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.80      0.83      0.81       809\n",
      "           A       0.93      0.92      0.93      2102\n",
      "\n",
      "    accuracy                           0.89      2911\n",
      "   macro avg       0.86      0.87      0.87      2911\n",
      "weighted avg       0.89      0.89      0.89      2911\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, hb_train_loader, criterion, optimizer, hb_test_loader, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
